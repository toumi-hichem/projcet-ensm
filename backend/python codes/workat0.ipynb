{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa1be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b6eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_23080\\4139433559.py:1: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"df_with_durations_02.csv\", parse_dates=[\"date\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_with_durations_02.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f255b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-event frequencies:\n",
      "Recevoir envoi au bureau d'échange (Ent) 856,063\n",
      "Expédition d'envoi à l'étranger (EDI-reçu) 820,530\n",
      "Expédier envoi à adresse nationale (Ent) 176,056\n",
      "Recevoir envoi au bureau de livraison (Ent) 36,282\n",
      "Expédier envoi à adresse nationale (Srt) 19,621\n",
      "Vaine tentative de livraison d'envoi (Ent) 3,697\n",
      "Transmettre envoi à l'agent de livraison (Ent) 1,561\n",
      "Recevoir envoi au bureau d'échange (Srt) 1,408\n",
      "Livraison d'envoi (Ent)                  1,308\n",
      "Enregistrer détails d'envoi au bureau d'échange (Srt) 753\n",
      "Expédier envoi à la douane (Ent)         718\n",
      "Renvoyer envoi de la douane (Ent)        169\n",
      "Insérer envoi dans sac (Srt)             86\n",
      "Mettre à jour envoi (Ent)                4\n",
      "Recevoir envoi au lieu (Ent)             3\n",
      "Renvoyer envoi de la douane (Srt)        2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ID_COL    = \"MAILITM_FID\"\n",
    "EVENT_COL = \"EVENT_TYPE_NM\"\n",
    "\n",
    "# 1) pick the first row per parcel (rows are already in correct order)\n",
    "first_events = (\n",
    "    df.groupby(ID_COL, sort=False)[EVENT_COL]\n",
    "      .first()                 # a Series: index = parcel ID, value = first event\n",
    ")\n",
    "\n",
    "# 2) count how many parcels have each first event\n",
    "event_counts = (\n",
    "    first_events.value_counts()   # Series: index = event, value = count\n",
    "               .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# 3) print the result\n",
    "print(\"First-event frequencies:\")\n",
    "for event, count in event_counts.items():\n",
    "    print(f\"{event:40} {count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fdcb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-event frequencies:\n",
      "Recevoir envoi au bureau d'échange (Ent)      4,453,297\n",
      "Insérer envoi dans sac (Srt)                  2,136,287\n",
      "Expédier envoi à adresse nationale (Ent)      1,851,919\n",
      "Réception d'envoi du client (Srt)             1,824,480\n",
      "Expédition d'envoi à l'étranger (EDI-reçu)    1,435,768\n",
      "Recevoir envoi au bureau de livraison (Ent)   514,493\n",
      "Expédier envoi à adresse nationale (Srt)      296,117\n",
      "Vaine tentative de livraison d'envoi (Ent)    48,900\n",
      "Enregistrer détails d'envoi au bureau d'échange (Srt) 36,655\n",
      "Transmettre envoi à l'agent de livraison (Ent) 25,731\n",
      "Livraison d'envoi (Ent)                       22,616\n",
      "Expédier envoi à la douane (Ent)              13,912\n",
      "Recevoir envoi au bureau d'échange (Srt)      4,330\n",
      "Renvoyer envoi de la douane (Ent)             2,430\n",
      "Mettre à jour envoi (Ent)                     456\n",
      "Renvoyer envoi de la douane (Srt)             103\n",
      "Recevoir envoi au lieu (Ent)                  64\n",
      "Enregistrer informations douanières d'envoi (Ent) 37\n",
      "Enregistrer raison de rétention d'envoi par la douane (Srt) 23\n",
      "Recevoir envoi au lieu (Srt)                  6\n",
      "Garder envoi au point de livraison (Ent)      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEMPLATE   = \"df_with_durations_0{}.csv\"  # The file name pattern\n",
    "FILE_RANGE = range(1, 8)  # For files 1 to 7\n",
    "ID_COL     = \"MAILITM_FID\"\n",
    "EVENT_COL  = \"EVENT_TYPE_NM\"\n",
    "\n",
    "# Initialize a dictionary to hold the counts for each event\n",
    "event_counts = {}\n",
    "\n",
    "for n in FILE_RANGE:\n",
    "    # Read each file\n",
    "    df = pd.read_csv(TEMPLATE.format(n), usecols=[ID_COL, EVENT_COL])\n",
    "\n",
    "    # 1) Get the first event per parcel\n",
    "    first_events = (\n",
    "        df.groupby(ID_COL, sort=False)[EVENT_COL]\n",
    "          .first()  # First event for each parcel\n",
    "    )\n",
    "\n",
    "    # 2) Count how many parcels have each first event\n",
    "    for event, count in first_events.value_counts().items():\n",
    "        if event in event_counts:\n",
    "            event_counts[event] += count  # Add count if the event already exists\n",
    "        else:\n",
    "            event_counts[event] = count  # Create new count if event is new\n",
    "\n",
    "    # Free up memory after processing the file\n",
    "    del df\n",
    "\n",
    "# 3) Print the sorted event counts\n",
    "print(\"First-event frequencies:\")\n",
    "sorted_event_counts = sorted(event_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for event, count in sorted_event_counts:\n",
    "    print(f\"{event:45} {count:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424491a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of first events: 12,667,625\n"
     ]
    }
   ],
   "source": [
    "# Sum all the counts in event_counts\n",
    "total_first_events = sum(event_counts.values())\n",
    "\n",
    "# Print the total number of first events\n",
    "print(f\"Total number of first events: {total_first_events:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb033b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAILITM_FID  Count\n",
      "0        CA000020800LY      4\n",
      "1        CA000020844RU      1\n",
      "2        CA000086085US      4\n",
      "3        CA000094303US      4\n",
      "4        CA000102985US      4\n",
      "...                ...    ...\n",
      "4584811  ua676178693ae      1\n",
      "4584812  ua676214078ae      1\n",
      "4584813  ua676215060ae      1\n",
      "4584814  ua676365705ae      1\n",
      "4584815  ua676401053ae      1\n",
      "\n",
      "[4584816 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEMPLATE   = \"df_with_durations_0{}.csv\"  # The file name pattern\n",
    "FILE_RANGE = range(1, 8)  # For files 1 to 7\n",
    "ID_COL     = \"MAILITM_FID\"\n",
    "\n",
    "# Initialize an empty list to store all MAILITM_FID values (unique per file)\n",
    "all_mais = []\n",
    "\n",
    "for n in FILE_RANGE:\n",
    "    # Read the current file\n",
    "    df = pd.read_csv(TEMPLATE.format(n), usecols=[ID_COL])\n",
    "\n",
    "    # Get the unique MAILITM_FID values from the current file\n",
    "    unique_mais = df[ID_COL].unique()\n",
    "\n",
    "    # Append the unique values to the list\n",
    "    all_mais.extend(unique_mais)\n",
    "\n",
    "    # Free up memory after processing the file\n",
    "    del df\n",
    "\n",
    "# Create a DataFrame with all unique MAILITM_FID values across all files\n",
    "df_all_mais = pd.DataFrame(all_mais, columns=[ID_COL])\n",
    "\n",
    "# Get the count of each unique MAILITM_FID\n",
    "df_mai_count = df_all_mais.groupby(ID_COL).size().reset_index(name='Count')\n",
    "\n",
    "# Show the resulting DataFrame with unique MAILITM_FID and their counts\n",
    "print(df_mai_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69accd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12667625, 1)\n",
      "(4584816, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_all_mais.shape)\n",
    "print(df_mai_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "960281a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrence of counts:\n",
      "1: 80,315\n",
      "2: 1,656,858\n",
      "3: 2,116,978\n",
      "4: 730,665\n",
      "Total: 4,584,816\n",
      "all: 12,667,625\n"
     ]
    }
   ],
   "source": [
    "# Get the number of occurrences for each count (1, 2, 3, etc.)\n",
    "occurrence_counts = df_mai_count['Count'].value_counts().sort_index()\n",
    "\n",
    "# Print the result: how many times each occurrence count happens\n",
    "print(\"Occurrence of counts:\")\n",
    "s = 0\n",
    "l = 0\n",
    "for count, num_occurrences in occurrence_counts.items():\n",
    "    s += num_occurrences\n",
    "    l += num_occurrences * count\n",
    "    print(f\"{count}: {num_occurrences:,}\")\n",
    "print(f\"Total: {s:,}\")\n",
    "print(f\"all: {l:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1907f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mai_count saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save df_mai_count to a CSV file\n",
    "df_mai_count.to_csv(\"df_mai_count.csv\", index=False)\n",
    "print(\"df_mai_count saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46081bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_mai_count read successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read df_mai_count from the saved CSV file to optimize memory\n",
    "df_mai_count = pd.read_csv(\"df_mai_count.csv\")\n",
    "print(\"df_mai_count read successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8ce57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4584816, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mai_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e9e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows for MAI values with Count == 1: 580,983\n",
      "Total rows for MAI values with Count == 2: 17,512,090\n",
      "Total rows for MAI values with Count == 3: 24,073,122\n",
      "Total rows for MAI values with Count == 4: 9,170,982\n",
      "Sum of rows for Count 1, 2, 3, and 4: 51,337,177\n",
      "Total rows across all datasets: 51,337,177\n",
      "The sum of rows for Count 1, 2, 3, and 4 matches the total rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEMPLATE   = \"df_with_durations_0{}.csv\"  # The file name pattern\n",
    "FILE_RANGE = range(1, 8)  # For files 1 to 7\n",
    "ID_COL     = \"MAILITM_FID\"\n",
    "\n",
    "# Initialize variables to count total rows for different counts of MAI\n",
    "total_rows_count_1 = 0\n",
    "total_rows_count_2 = 0\n",
    "total_rows_count_3 = 0\n",
    "total_rows_count_4 = 0\n",
    "total_rows_all_files = 0  # Total rows across all datasets\n",
    "\n",
    "# Get the list of MAI values with Count 1, 2, 3, and 4\n",
    "ma_count_1 = df_mai_count[df_mai_count['Count'] == 1][ID_COL]\n",
    "ma_count_2 = df_mai_count[df_mai_count['Count'] == 2][ID_COL]\n",
    "ma_count_3 = df_mai_count[df_mai_count['Count'] == 3][ID_COL]\n",
    "ma_count_4 = df_mai_count[df_mai_count['Count'] == 4][ID_COL]\n",
    "\n",
    "# Loop through the files and count the rows for each set of MAI values\n",
    "for n in FILE_RANGE:\n",
    "    # Read the current file\n",
    "    df = pd.read_csv(TEMPLATE.format(n), usecols=[ID_COL])\n",
    "\n",
    "    # Count how many rows have a MAILITM_FID from each of the lists\n",
    "    total_rows_count_1 += df[df[ID_COL].isin(ma_count_1)].shape[0]\n",
    "    total_rows_count_2 += df[df[ID_COL].isin(ma_count_2)].shape[0]\n",
    "    total_rows_count_3 += df[df[ID_COL].isin(ma_count_3)].shape[0]\n",
    "    total_rows_count_4 += df[df[ID_COL].isin(ma_count_4)].shape[0]\n",
    "\n",
    "    # Count total rows in the current dataset\n",
    "    total_rows_all_files += df.shape[0]\n",
    "\n",
    "    # Free up memory after processing the file\n",
    "    del df\n",
    "\n",
    "# Print the total rows for each count\n",
    "print(f\"Total rows for MAI values with Count == 1: {total_rows_count_1:,}\")\n",
    "print(f\"Total rows for MAI values with Count == 2: {total_rows_count_2:,}\")\n",
    "print(f\"Total rows for MAI values with Count == 3: {total_rows_count_3:,}\")\n",
    "print(f\"Total rows for MAI values with Count == 4: {total_rows_count_4:,}\")\n",
    "\n",
    "# Compare the sum of the counts with the total number of rows\n",
    "sum_of_counts = total_rows_count_1 + total_rows_count_2 + total_rows_count_3 + total_rows_count_4\n",
    "print(f\"Sum of rows for Count 1, 2, 3, and 4: {sum_of_counts:,}\")\n",
    "print(f\"Total rows across all datasets: {total_rows_all_files:,}\")\n",
    "\n",
    "# Verify if the sum matches the total rows\n",
    "if sum_of_counts == total_rows_all_files:\n",
    "    print(\"The sum of rows for Count 1, 2, 3, and 4 matches the total rows.\")\n",
    "else:\n",
    "    print(\"The sum of rows for Count 1, 2, 3, and 4 does not match the total rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775eabe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_18156\\3747614296.py:28: DtypeWarning: Columns (0,4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(TEMPLATE.format(n))\n",
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_18156\\3747614296.py:28: DtypeWarning: Columns (0,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(TEMPLATE.format(n))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_count_1.csv saved successfully.\n",
      "df_count_2_part1.csv saved successfully.\n",
      "df_count_2_part2.csv saved successfully.\n",
      "df_count_3_part1.csv saved successfully.\n",
      "df_count_3_part2.csv saved successfully.\n",
      "df_count_4.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "TEMPLATE   = \"df_with_durations_0{}.csv\"  # The file name pattern\n",
    "FILE_RANGE = range(1, 8)  # For files 1 to 7\n",
    "ID_COL     = \"MAILITM_FID\"\n",
    "EVENT_COL  = \"EVENT_TYPE_NM\"\n",
    "DATE_COL   = \"date\"  # Assuming you have a column with the date/time of events (update if needed)\n",
    "\n",
    "# Helper function to write the dataset to CSV\n",
    "def save_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"{filename} saved successfully.\")\n",
    "\n",
    "# Initialize lists for each dataset\n",
    "df_count_1 = []\n",
    "df_count_2 = []\n",
    "df_count_3 = []\n",
    "df_count_4 = []\n",
    "\n",
    "ma_count_1 = df_mai_count[df_mai_count['Count'] == 1][ID_COL]\n",
    "ma_count_2 = df_mai_count[df_mai_count['Count'] == 2][ID_COL]\n",
    "ma_count_3 = df_mai_count[df_mai_count['Count'] == 3][ID_COL]\n",
    "ma_count_4 = df_mai_count[df_mai_count['Count'] == 4][ID_COL]\n",
    "\n",
    "# Process the files and collect rows based on their count\n",
    "for n in FILE_RANGE:\n",
    "    # Read the current file, including all columns\n",
    "    df = pd.read_csv(TEMPLATE.format(n))\n",
    "\n",
    "    # Sort by MAILITM_FID and DATE to ensure rows are ordered within each package\n",
    "    df = df.sort_values(by=[ID_COL, DATE_COL])\n",
    "\n",
    "    # Get the MAI values with Count == 1, 2, 3, and 4 (these should have been precomputed)\n",
    "    df_count_1_rows = df[df[ID_COL].isin(ma_count_1)]\n",
    "    df_count_2_rows = df[df[ID_COL].isin(ma_count_2)]\n",
    "    df_count_3_rows = df[df[ID_COL].isin(ma_count_3)]\n",
    "    df_count_4_rows = df[df[ID_COL].isin(ma_count_4)]\n",
    "\n",
    "    # Append the rows for Count 1, 2, 3, and 4\n",
    "    df_count_1.append(df_count_1_rows)\n",
    "    df_count_2.append(df_count_2_rows)\n",
    "    df_count_3.append(df_count_3_rows)\n",
    "    df_count_4.append(df_count_4_rows)\n",
    "\n",
    "    # Free up memory after processing the file\n",
    "    del df\n",
    "\n",
    "# Create DataFrames for Count 1, 2, 3, and 4 datasets\n",
    "df_count_1 = pd.concat(df_count_1, ignore_index=True)\n",
    "df_count_2 = pd.concat(df_count_2, ignore_index=True)\n",
    "df_count_3 = pd.concat(df_count_3, ignore_index=True)\n",
    "df_count_4 = pd.concat(df_count_4, ignore_index=True)\n",
    "\n",
    "# Split Count 2 into two balanced datasets (by `MAILITM_FID`)\n",
    "unique_2 = df_count_2[ID_COL].unique()\n",
    "half_len_2 = len(unique_2) // 2\n",
    "df_count_2_1 = df_count_2[df_count_2[ID_COL].isin(unique_2[:half_len_2])]\n",
    "df_count_2_2 = df_count_2[df_count_2[ID_COL].isin(unique_2[half_len_2:])]\n",
    "\n",
    "# Split Count 3 into two balanced datasets (by `MAILITM_FID`)\n",
    "unique_3 = df_count_3[ID_COL].unique()\n",
    "half_len_3 = len(unique_3) // 2\n",
    "df_count_3_1 = df_count_3[df_count_3[ID_COL].isin(unique_3[:half_len_3])]\n",
    "df_count_3_2 = df_count_3[df_count_3[ID_COL].isin(unique_3[half_len_3:])]\n",
    "\n",
    "# Save the datasets to CSV\n",
    "save_to_csv(df_count_1, \"df_count_1.csv\")\n",
    "\n",
    "# Save split datasets for Count 2\n",
    "save_to_csv(df_count_2_1, \"df_count_2_part1.csv\")\n",
    "save_to_csv(df_count_2_2, \"df_count_2_part2.csv\")\n",
    "\n",
    "# Save split datasets for Count 3\n",
    "save_to_csv(df_count_3_1, \"df_count_3_part1.csv\")\n",
    "save_to_csv(df_count_3_2, \"df_count_3_part2.csv\")\n",
    "\n",
    "# Save the dataset for Count 4\n",
    "save_to_csv(df_count_4, \"df_count_4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba8baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_1.csv: 580,983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_2_part1.csv: 8,702,225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (0,4,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_2_part2.csv: 8,809,865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_3_part1.csv: 11,785,664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_3_part2.csv: 12,287,458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oussa\\AppData\\Local\\Temp\\ipykernel_22324\\1888072253.py:19: DtypeWarning: Columns (0,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df_count_4.csv: 9,170,982\n",
      "\n",
      "Total rows across all datasets: 51,337,177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset filenames\n",
    "files = [\n",
    "    \"df_count_1.csv\",\n",
    "    \"df_count_2_part1.csv\",\n",
    "    \"df_count_2_part2.csv\",\n",
    "    \"df_count_3_part1.csv\",\n",
    "    \"df_count_3_part2.csv\",\n",
    "    \"df_count_4.csv\"\n",
    "]\n",
    "\n",
    "# Initialize a variable to hold the total row count\n",
    "total_rows = 0\n",
    "\n",
    "# Iterate over the list of files\n",
    "for file in files:\n",
    "    # Read the current file\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Count the number of rows in the current dataset\n",
    "    rows_count = df.shape[0]\n",
    "    total_rows += rows_count\n",
    "\n",
    "    # Print the row count for the current file\n",
    "    print(f\"Rows in {file}: {rows_count:,}\")\n",
    "\n",
    "    # Free up memory by deleting the dataframe\n",
    "    del df\n",
    "\n",
    "# Print the total row count across all datasets\n",
    "print(f\"\\nTotal rows across all datasets: {total_rows:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d20fb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e7d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
